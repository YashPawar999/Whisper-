# Whisper-
Whisper model for Speech to Text Recognition 
# ğŸ™ï¸ Real-Time English Speech-to-Text (CPU) using Faster-Whisper

## ğŸ“Œ Overview

This project implements a **real-time English speech-to-text system** using a microphone and a pretrained Whisper model.

It captures live audio from the system microphone, filters noise, and transcribes spoken English into text using **Faster-Whisper** optimized for CPU execution.

This system can be used in:

* Voice assistants
* Accessibility tools
* Meeting transcription systems
* Voice-controlled applications
* Game voice command systems
* AI chatbot input pipelines

---

## âš™ï¸ How It Works

### 1. Audio Capture

The system continuously records audio from the microphone using `sounddevice`.

Audio is captured in small chunks (~1.2 seconds).

```
Microphone â†’ Audio Chunk â†’ Processing Pipeline
```

---

### 2. Noise Filtering

Before sending audio to the model, the system removes low-energy signals:

* Peak amplitude threshold removes silence
* Energy threshold removes background noise

This reduces unnecessary transcription calls and improves accuracy.

---

### 3. Speech Recognition Model

The project uses:

**Faster-Whisper (`base.en`)**

* Transformer-based ASR model
* Pretrained on large multilingual speech datasets
* Optimized for CPU inference using INT8 quantization

The model converts speech directly into English text without needing phonemes, HMMs, or manual training.

---

### 4. Transcription Pipeline

```
Mic Input
   â†“
Audio Chunking
   â†“
Noise Filtering
   â†“
Whisper Encoderâ€“Decoder
   â†“
Text Output
```

Each valid chunk is transcribed and printed to the terminal.

---

## ğŸ–¥ï¸ Requirements

### Python

* Python 3.9 â€“ 3.11 recommended

### Install dependencies

```bash
pip install faster-whisper sounddevice numpy
```

If needed:

```bash
pip install torch --index-url https://download.pytorch.org/whl/cpu
```

---

## â–¶ï¸ How To Run

1. Clone repository

```bash
git clone <repo_url>
cd <repo_name>
```

2. Run the script

```bash
python realtime_whisper.py
```

3. Speak into the microphone
4. Transcription appears in terminal
5. Stop with:

```
Ctrl + C
```

---

## ğŸ”Œ How To Integrate Into Another Project

### Option 1 â€” Import as a module

Refactor the transcription loop into a function:

```python
def transcribe_audio_chunk(audio_chunk):
    segments, _ = model.transcribe(
        audio_chunk,
        language="en",
        beam_size=2,
        temperature=0.0,
        vad_filter=True
    )
    return " ".join([s.text.strip() for s in segments])
```

You can then call this function from:

* a GUI app
* a web API
* a game engine bridge
* a chatbot backend
* a real-time subtitle system

---

### Option 2 â€” Use as a background worker

The script can be wrapped inside:

* Flask / FastAPI server
* WebSocket streaming service
* Desktop assistant
* Game voice input thread

Example integration flow:

```
Frontend Mic â†’ Backend Python Service â†’ Whisper â†’ Text â†’ Application Logic
```

---

## ğŸ“‚ Project Structure

```
project/
â”‚â”€â”€ realtime_whisper.py
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt (optional)
```

---

## ğŸš€ Possible Improvements

* Continuous streaming transcription (rolling buffer)
* Sentence segmentation
* Punctuation restoration
* Voice activity detection tuning
* GPU acceleration support
* REST API wrapper
* GUI interface
* Multilingual support

---

## ğŸ§  Model Notes

| Feature | Value                          |
| ------- | ------------------------------ |
| Model   | Whisper base.en                |
| Runtime | CPU (INT8)                     |
| Latency | ~1â€“3 sec depending on hardware |
| Input   | Microphone audio               |
| Output  | English text                   |

---

## ğŸ“œ License

Use according to Whisper and Faster-Whisper licenses.

---

## ğŸ‘¤ Author

Developed as a real-time ASR prototype for integration into AI and voice-enabled systems.
